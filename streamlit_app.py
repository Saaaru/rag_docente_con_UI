import streamlit as st
import uuid
import os
from datetime import datetime
import sys

# Configuraci√≥n de la p√°gina - DEBE SER LA PRIMERA LLAMADA A STREAMLIT
st.set_page_config(
    page_title="Asistente Docente Chileno",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Importar las funciones necesarias del archivo principal
from app import (
    load_dotenv,
    VertexAIEmbeddings, 
    ChatVertexAI,
    Chroma,
    create_planning_agent,
    create_evaluation_agent,
    create_study_guide_agent,
    create_router_agent,
    format_and_save_conversation
)

# Cargar variables de entorno
dotenv_path = os.path.join(os.path.dirname(__file__), 'db', '.env')
load_dotenv(dotenv_path)

# Credenciales para usar VERTEX_AI
credentials_path = r"C:/Users/mfuen/OneDrive/Desktop/rag_docente_con_UI/db/gen-lang-client-0115469242-239dc466873d.json"
if not os.path.exists(credentials_path):
    st.error(f"No se encontr√≥ el archivo de credenciales en: {credentials_path}")
    st.stop()
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path

# Para tracear con langsmith
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
if not LANGSMITH_API_KEY:
    st.error("La variable LANGSMITH_API_KEY no est√° definida en el archivo .env en la carpeta db/")
    st.stop()
os.environ["LANGSMITH_API_KEY"] = LANGSMITH_API_KEY
os.environ["LANGSMITH_TRACING"] = "true"

# Modificar la funci√≥n initialize_resources para que no muestre spinner
@st.cache_resource(show_spinner=False)  # Removemos el spinner de la cache
def initialize_resources():
    """
    Inicializa los recursos necesarios para el sistema.
    No debe contener elementos de UI de Streamlit.
    """
    llm = ChatVertexAI(
        model_name="gemini-1.5-flash",
        temperature=0.5,
        max_output_tokens=8192,
        top_p=0.95,
        top_k=40
    )

    embeddings = VertexAIEmbeddings(model_name="text-multilingual-embedding-002")
    
    collection_name = "pdf-rag-chroma"
    persist_directory = f"./{collection_name}"
    
    vectorstore = Chroma(
        persist_directory=persist_directory,
        embedding_function=embeddings,
        collection_name=collection_name
    )
    
    planning_agent = create_planning_agent(llm, vectorstore)
    evaluation_agent = create_evaluation_agent(llm, vectorstore)
    study_guide_agent = create_study_guide_agent(llm, vectorstore)
    router = create_router_agent(llm, planning_agent, evaluation_agent, study_guide_agent)
    
    return router, llm, vectorstore

# Funci√≥n para mostrar mensajes con formato adecuado
def display_message(role, content, avatar=None):
    with st.chat_message(role, avatar=avatar):
        st.markdown(content)

# Inicializar historial si no existe
def initialize_session():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = str(uuid.uuid4())[:8]
    if "pending_request" not in st.session_state:
        st.session_state.pending_request = False
    if "last_query" not in st.session_state:
        st.session_state.last_query = ""
    if "asignatura" not in st.session_state:
        st.session_state.asignatura = None
    if "nivel" not in st.session_state:
        st.session_state.nivel = None
    if "tipo" not in st.session_state:
        st.session_state.tipo = None

def main():
    # Ya no incluimos st.set_page_config() aqu√≠
    initialize_session()
    
    # Verificaciones de archivos y credenciales
    if not os.path.exists(credentials_path):
        st.error(f"No se encontr√≥ el archivo de credenciales en: {credentials_path}")
        st.stop()

    collection_name = "pdf-rag-chroma"
    persist_directory = f"./{collection_name}"
    
    if not os.path.exists(persist_directory):
        st.error("No se encontr√≥ la base de datos. Por favor, ejecuta app.py primero para crearla.")
        st.stop()

    # Sidebar con informaci√≥n
    with st.sidebar:
        st.title("Asistente Docente Chileno")
        st.markdown("---")
        st.markdown("### üìù Tipo de contenidos")
        st.markdown("- **Planificaciones educativas** (planes de clase, anuales, etc.)")
        st.markdown("- **Evaluaciones** (pruebas, ex√°menes, etc.)")
        st.markdown("- **Gu√≠as de estudio** (material para estudiantes)")
        st.markdown("---")
        st.markdown(f"üîë ID de sesi√≥n: `{st.session_state.thread_id}`")
        
        # Bot√≥n para descargar la conversaci√≥n actual
        if st.button("üíæ Descargar conversaci√≥n"):
            # Generar contenido markdown de la conversaci√≥n
            markdown_content = "# Conversaci√≥n con Asistente Docente\n\n"
            markdown_content += f"Fecha: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n"
            markdown_content += f"ID de sesi√≥n: {st.session_state.thread_id}\n\n"
            markdown_content += "---\n\n"
            
            for msg in st.session_state.messages:
                role = "Usuario" if msg["role"] == "user" else "Asistente"
                markdown_content += f"## {role}\n\n{msg['content']}\n\n---\n\n"
            
            # Crear archivo temporal para descarga
            filename = f"conversacion_{st.session_state.thread_id}.md"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            
            # Ofrecer descarga
            with open(filename, "r", encoding="utf-8") as f:
                st.download_button(
                    label="üì• Descargar archivo Markdown",
                    data=f,
                    file_name=filename,
                    mime="text/markdown"
                )
        
        st.markdown("---")
        st.markdown("### üëã Iniciar nueva conversaci√≥n")
        if st.button("Nueva conversaci√≥n"):
            st.session_state.messages = []
            st.session_state.thread_id = str(uuid.uuid4())[:8]
            st.session_state.pending_request = False
            st.session_state.last_query = ""
            st.session_state.asignatura = None
            st.session_state.nivel = None
            st.session_state.tipo = None
            st.rerun()
    
    # T√≠tulo principal
    st.title("üí¨ Chat con Asistente Docente")
    st.markdown("Consulta sobre planificaciones, evaluaciones o gu√≠as de estudio para el sistema educativo chileno.")
    
    # Inicializar recursos silenciosamente
    router, llm, vectorstore = initialize_resources()
    
    # Contenedor para los mensajes
    chat_container = st.container()
    
    with chat_container:
        # Mostrar mensajes anteriores
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # Mensaje de bienvenida si no hay mensajes
        if not st.session_state.messages:
            with st.chat_message("assistant"):
                st.markdown("""
                üëã ¬°Hola! Soy tu asistente para crear contenido educativo para el sistema chileno.
                
                Puedo ayudarte con:
                - **Planificaciones** para cualquier nivel y asignatura
                - **Evaluaciones** alineadas con el curr√≠culum nacional
                - **Gu√≠as de estudio** para tus estudiantes
                
                ¬øEn qu√© puedo ayudarte hoy?
                """)
    
    # Campo de entrada de texto
    user_input = st.chat_input("Escribe tu consulta aqu√≠...")
    
    # Procesar el input del usuario
    if user_input:
        # Mostrar mensaje del usuario inmediatamente
        with chat_container:
            with st.chat_message("user"):
                st.markdown(user_input)
        
        # Guardar mensaje del usuario en el historial
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # Crear un contenedor espec√≠fico para la respuesta del asistente
        with chat_container:
            with st.chat_message("assistant"):
                try:
                    # Peque√±o indicador de "Procesando..."
                    processing_placeholder = st.empty()
                    processing_placeholder.markdown("*Procesando tu solicitud...*")
                    
                    # Procesar la solicitud
                    if st.session_state.pending_request:
                        if not st.session_state.asignatura:
                            st.session_state.asignatura = user_input
                            response, needs_info, info, tipo = router(
                                st.session_state.last_query, 
                                st.session_state.asignatura, 
                                st.session_state.nivel
                            )
                        elif not st.session_state.nivel:
                            st.session_state.nivel = user_input
                            response, needs_info, info, tipo = router(
                                st.session_state.last_query, 
                                st.session_state.asignatura, 
                                st.session_state.nivel
                            )
                    else:
                        # Nueva solicitud
                        response, needs_info, info, tipo = router(user_input)
                    
                    # Eliminar el indicador de "Procesando..."
                    processing_placeholder.empty()
                    
                    # Mostrar la respuesta
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    # Actualizar el estado seg√∫n la respuesta
                    if needs_info:
                        st.session_state.pending_request = True
                        st.session_state.last_query = user_input
                        st.session_state.asignatura = info.get("asignatura")
                        st.session_state.nivel = info.get("nivel")
                        st.session_state.tipo = tipo
                    else:
                        format_and_save_conversation(user_input, response, st.session_state.thread_id)
                        # Reiniciar el estado
                        st.session_state.pending_request = False
                        st.session_state.last_query = ""
                        st.session_state.asignatura = None
                        st.session_state.nivel = None
                        st.session_state.tipo = None
                
                except Exception as e:
                    error_message = f"‚ùå Lo siento, ocurri√≥ un error: {str(e)}\n\nPor favor, intenta reformular tu solicitud."
                    st.markdown(error_message)
                    st.session_state.messages.append({"role": "assistant", "content": error_message})
                    # Reiniciar el estado en caso de error
                    st.session_state.pending_request = False
                    st.session_state.last_query = ""
                    st.session_state.asignatura = None
                    st.session_state.nivel = None
                    st.session_state.tipo = None

if __name__ == "__main__":
    main() 